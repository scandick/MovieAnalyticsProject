{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294db3c8-c007-4eef-a8d8-1e46ec40d0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0732e465",
   "metadata": {},
   "source": [
    "Для создания рабочего датасета собрали фильмы отсортированные по сборам в США года с 1975 по 2025.  \n",
    "Примерное время парсинга 1,5 часа.  \n",
    "Как работает парсер:  \n",
    "1. Собираем ссылки на списки из 100 фильмов отсортированные по сборам на выбранные года.\n",
    "\n",
    "2. Создаю csv файл, в которые буду записывать, полученную информацию.\n",
    "\n",
    "3. С помощью селениум и вебдрайвер открывается страница списка из 100 фильмов в автоновном режиме, и собирает место из списка и ссылку на фильм. (Использовали селениум, так как через реквест выдавало только 25 фильмов, хотя в ссылке был параметр &count=100)\n",
    "\n",
    "4. Алгоритм проходится по каждой ссылке и парсит такую информацию, как название, рейтинг, продолжительность в минутах, режисер, жанр, датарелиза, страна производства, компания производитель, бюджет, сборы в США, сборы по миру, сборы в первые выходные.\n",
    "htmlтекст получаю через реквест. Cайт IMDB строиться частично динамически, почти все классы это уникальные строки, которые создаются при открытии ссылки, но у них есть неуникальный параметр {data_test_id}, поиск по которому и позволил получить большую часть информации.\n",
    "\n",
    "5. После обработки одного года записываю информацию в файл и очищаю переменную data содержащую информацию о фильмах одного года."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4feb35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_year = 1975\n",
    "end_year = 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc1555f",
   "metadata": {},
   "source": [
    "Для пример можно взять два года.  \n",
    "Примерное время парсинга 6-7 минут."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fba4587a",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_year = 2017\n",
    "end_year = 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9236a0",
   "metadata": {},
   "source": [
    "1. Собираем ссылки на списки из 100 фильмов отсортированные по сборам на выбранные года."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d76e3fcf-5d1d-4f28-8eb2-692f15f61cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 100\n",
    "\n",
    "urls = list()\n",
    "\n",
    "for year in range(start_year, end_year + 1):\n",
    "\n",
    "    url = f\"https://www.imdb.com/search/title/?title_type=feature&release_date={year}-01-01,{year}-12-31&count={count}&sort=boxoffice_gross_us,desc\"\n",
    "    urls.append(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "38ade9bb-243c-4cc8-b8c0-ce051ea9258f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.imdb.com/search/title/?title_type=feature&release_date=2017-01-01,2017-12-31&count=100&sort=boxoffice_gross_us,desc\n"
     ]
    }
   ],
   "source": [
    "print(*urls, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880a1685",
   "metadata": {},
   "source": [
    "2. Создаю csv файл, в которые буду записывать, полученную информацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f085d646",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.writer(f, delimiter=';')\n",
    "    csv_header = ['year', 'place', 'title', 'rating', 'min',\n",
    "                    'director', 'genre', 'release_date', 'origin_country',\n",
    "                    'company', 'budget', 'gross_us', 'gross_world', 'open_week']\n",
    "    \n",
    "    writer.writerow(csv_header)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ddb0c0",
   "metadata": {},
   "source": [
    "4. Алгоритм проходится по каждой ссылке и парсит такую информацию, как название, рейтинг, продолжительность в минутах, режисер, жанр, датарелиза, страна производства, компания производитель, бюджет, сборы в США, сборы по миру, сборы в первые выходные.\n",
    "htmlтекст получаю через реквест. Cайт IMDB строиться частично динамически, почти все классы это уникальные строки, которые создаются при открытии ссылки, но у них есть неуникальный параметр {data_test_id}, поиск по которому и позволил получить большую часть информации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b3c0b7-9c46-427e-b447-2b0540d6983c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info_from_url(html, headers, data):\n",
    "    \n",
    "    year = get_year(url)\n",
    "    \n",
    "    movie_url_start = \"https://www.imdb.com\"\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    movies = soup.select(\".ipc-metadata-list-summary-item\")\n",
    "    print(len(movies))\n",
    "    \n",
    "    for movie in movies:\n",
    "        movie_data = list()\n",
    "        movie_data.append(year)\n",
    "        link = movie.select(\".ipc-title-link-wrapper\")[0]\n",
    "        place = link.text.split('.')[0].strip()\n",
    "        movie_data.append(place)\n",
    "\n",
    "        movie_url = movie_url_start + link.get('href')   \n",
    "        get_info_from_movie_url(movie_url, headers, movie_data)\n",
    "        data.append(movie_data)\n",
    "        print(movie_data[0], movie_data[1])\n",
    "\n",
    "\n",
    "def get_info_from_movie_url(url, headers, movie_data):\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    title = get_text_from_class(soup, \".hero__primary-text\")\n",
    "   \n",
    "    rating_obj = soup.find(attrs={\"data-testid\": \"hero-rating-bar__aggregate-rating__score\"})\n",
    "\n",
    "    if type(rating_obj) != type(None):\n",
    "        rating = rating_obj.find(\"span\")\n",
    "        if type(rating) != type(None):\n",
    "            rating = rating.text\n",
    "        else:\n",
    "            rating = ''\n",
    "    else:\n",
    "        rating = ''\n",
    "\n",
    "    genre_obj = soup.find(class_=\"ipc-chip-list__scroller\")\n",
    "    genre_list = list()\n",
    "    if type(genre_obj) != type(None):\n",
    "        for genre in genre_obj.find_all(class_=\"ipc-chip__text\"):\n",
    "            genre_list.append(genre.text)\n",
    "    \n",
    "    director = soup.find(class_=\"ipc-metadata-list-item__list-content-item ipc-metadata-list-item__list-content-item--link\")\n",
    "    if type(director) != type(None):\n",
    "        director = director.text    \n",
    "    else:\n",
    "        director = ''\n",
    "\n",
    "\n",
    "    details_section = soup.find(attrs={\"data-testid\": \"title-details-section\"})\n",
    "\n",
    "    if type(details_section) != type(None):\n",
    "        release_date_section = details_section.find(attrs={\"data-testid\": \"title-details-releasedate\"})\n",
    "        if type(release_date_section) != type(None):\n",
    "            release_date = release_date_section.find(class_=\"ipc-metadata-list-item__list-content-item ipc-metadata-list-item__list-content-item--link\").text\n",
    "        else:\n",
    "            release_date = ''\n",
    "        \n",
    "        OriginCountry_section = details_section.find(attrs={\"data-testid\": \"title-details-origin\"})\n",
    "        if type(OriginCountry_section) != type(None):\n",
    "            OriginCountry = OriginCountry_section.find(class_=\"ipc-metadata-list-item__list-content-item ipc-metadata-list-item__list-content-item--link\").text\n",
    "        else:\n",
    "            OriginCountry = ''\n",
    "\n",
    "        Company_section = details_section.find(attrs={\"data-testid\": \"title-details-companies\"})\n",
    "        if type(Company_section) != type(None):\n",
    "            Company = Company_section.find(class_=\"ipc-metadata-list-item__list-content-item ipc-metadata-list-item__list-content-item--link\").text\n",
    "        else:\n",
    "            Company = ''\n",
    "    else:\n",
    "        release_date = ''\n",
    "        OriginCountry = ''\n",
    "        Company = ''\n",
    "\n",
    "    BoxOffice_section = soup.find(attrs={\"data-testid\": \"title-boxoffice-section\"})\n",
    "\n",
    "    if type(BoxOffice_section) != type(None):\n",
    "        budget_obj = BoxOffice_section.find(attrs={\"data-testid\": \"title-boxoffice-budget\"})\n",
    "        if type(budget_obj) != type(None):\n",
    "            budget = budget_obj.find(class_=\"ipc-metadata-list-item__list-content-item ipc-btn--not-interactable\").text\n",
    "        else:\n",
    "            budget = \"\"\n",
    "\n",
    "        grossdomestic_obj = BoxOffice_section.find(attrs={\"data-testid\": \"title-boxoffice-grossdomestic\"})\n",
    "        if type(grossdomestic_obj) != type(None):\n",
    "            grossdomestic = grossdomestic_obj.find(class_=\"ipc-metadata-list-item__list-content-item ipc-btn--not-interactable\").text\n",
    "        else:\n",
    "            grossdomestic = \"\"\n",
    "\n",
    "        openingweekenddomestic_obj = BoxOffice_section.find(attrs={\"data-testid\": \"title-boxoffice-openingweekenddomestic\"})\n",
    "        if type(openingweekenddomestic_obj) != type(None):\n",
    "            openingweekenddomestic = openingweekenddomestic_obj.find(class_=\"ipc-metadata-list-item__list-content-item ipc-btn--not-interactable\").text\n",
    "        else:\n",
    "            openingweekenddomestic = \"\"\n",
    "\n",
    "        cumulativeworldwidegross_obj = BoxOffice_section.find(attrs={\"data-testid\": \"title-boxoffice-cumulativeworldwidegross\"})\n",
    "        if type(cumulativeworldwidegross_obj) != type(None):\n",
    "            cumulativeworldwidegross = cumulativeworldwidegross_obj.find(class_=\"ipc-metadata-list-item__list-content-item ipc-btn--not-interactable\").text\n",
    "        else:\n",
    "            cumulativeworldwidegross = \"\"\n",
    "    else:\n",
    "        budget = \"\"\n",
    "        grossdomestic = \"\"\n",
    "        openingweekenddomestic = \"\"\n",
    "        cumulativeworldwidegross = \"\"\n",
    "\n",
    "    runtime_section = soup.find(attrs={\"data-testid\": \"title-techspec_runtime\"})    \n",
    "    if type(runtime_section) != type(None):\n",
    "        runtime_min = runtime_section.find(class_=\"ipc-metadata-list-item__list-content-item--subText\")\n",
    "        if type(runtime_min) != type(None):\n",
    "            runtime_min = runtime_min.text\n",
    "        else:\n",
    "            runtime_min = ''    \n",
    "    else:\n",
    "        runtime_min = ''\n",
    "\n",
    "    movie_data.append(title.strip())\n",
    "    movie_data.append(rating.strip())\n",
    "    movie_data.append(runtime_min.strip())\n",
    "    movie_data.append(director.strip())\n",
    "    movie_data.append(genre_list)\n",
    "    movie_data.append(release_date.strip())\n",
    "    movie_data.append(OriginCountry.strip())\n",
    "    movie_data.append(Company.strip())\n",
    "    movie_data.append(budget.strip())\n",
    "    movie_data.append(grossdomestic.strip())\n",
    "    movie_data.append(cumulativeworldwidegross.strip())\n",
    "    movie_data.append(openingweekenddomestic.strip())\n",
    "\n",
    "    \n",
    "    \n",
    "def get_text_from_class(soup, soup_class):\n",
    "    a_row = soup.select(soup_class)\n",
    "    if len(a_row) > 0:\n",
    "        a_row = a_row[0]\n",
    "        text = a_row.text\n",
    "    else:\n",
    "        text = \"\"\n",
    "    return text\n",
    "\n",
    "def get_year(url):\n",
    "    key = 'release_date='\n",
    "    start = url.find(key)\n",
    "\n",
    "    if start != -1:\n",
    "        year = url[start + len(key): start + len(key) + 4]\n",
    "    else:\n",
    "        year = '0000'\n",
    "    \n",
    "    return year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d091c4",
   "metadata": {},
   "source": [
    "3. С помощью селениум и вебдрайвер открывается страница списка из 100 фильмов в автоновном режиме, и собирает место из списка и ссылку на фильм. (Использовали селениум, так как через реквест выдавало только 25 фильмов, хотя в ссылке был параметр &count=100)\n",
    "\n",
    "5.После обработки одного года записываю информацию в файл и очищаю переменную data содержащую информацию о фильмах одного года."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d9eaff-ae88-413c-a6c4-c04d6fed7dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "2017 1\n",
      "2017 2\n",
      "2017 3\n",
      "2017 4\n",
      "2017 5\n",
      "2017 6\n",
      "2017 7\n",
      "2017 8\n",
      "2017 9\n",
      "2017 10\n",
      "2017 11\n",
      "2017 12\n",
      "2017 13\n",
      "2017 14\n",
      "2017 15\n",
      "2017 16\n",
      "2017 17\n",
      "2017 18\n",
      "2017 19\n",
      "2017 20\n",
      "2017 21\n",
      "2017 22\n",
      "2017 23\n",
      "2017 24\n",
      "2017 25\n",
      "2017 26\n",
      "2017 27\n",
      "2017 28\n",
      "2017 29\n",
      "2017 30\n",
      "2017 31\n",
      "2017 32\n",
      "2017 33\n",
      "2017 34\n",
      "2017 35\n",
      "2017 36\n",
      "2017 37\n",
      "2017 38\n",
      "2017 39\n",
      "2017 40\n",
      "2017 41\n",
      "2017 42\n",
      "2017 43\n",
      "2017 44\n",
      "2017 45\n",
      "2017 46\n",
      "2017 47\n",
      "2017 48\n",
      "2017 49\n",
      "2017 50\n",
      "2017 51\n",
      "2017 52\n",
      "2017 53\n",
      "2017 54\n",
      "2017 55\n",
      "2017 56\n",
      "2017 57\n",
      "2017 58\n",
      "2017 59\n",
      "2017 60\n",
      "2017 61\n",
      "2017 62\n",
      "2017 63\n",
      "2017 64\n",
      "2017 65\n",
      "2017 66\n",
      "2017 67\n",
      "2017 68\n",
      "2017 69\n",
      "2017 70\n",
      "2017 71\n",
      "2017 72\n",
      "2017 73\n",
      "2017 74\n",
      "2017 75\n",
      "2017 76\n",
      "2017 77\n",
      "2017 78\n",
      "2017 79\n",
      "2017 80\n",
      "2017 81\n",
      "2017 82\n",
      "2017 83\n",
      "2017 84\n",
      "2017 85\n",
      "2017 86\n",
      "2017 87\n",
      "2017 88\n",
      "2017 89\n",
      "2017 90\n",
      "2017 91\n",
      "2017 92\n",
      "2017 93\n",
      "2017 94\n",
      "2017 95\n",
      "2017 96\n",
      "2017 97\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m html \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mpage_source\n\u001b[0;32m     13\u001b[0m driver\u001b[38;5;241m.\u001b[39mquit()\n\u001b[1;32m---> 14\u001b[0m get_info_from_url(html, headers, data)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m, data)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m, newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "Cell \u001b[1;32mIn[22], line 20\u001b[0m, in \u001b[0;36mget_info_from_url\u001b[1;34m(html, headers, data)\u001b[0m\n\u001b[0;32m     17\u001b[0m movie_data\u001b[38;5;241m.\u001b[39mappend(place)\n\u001b[0;32m     19\u001b[0m movie_url \u001b[38;5;241m=\u001b[39m movie_url_start \u001b[38;5;241m+\u001b[39m link\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhref\u001b[39m\u001b[38;5;124m'\u001b[39m)   \n\u001b[1;32m---> 20\u001b[0m get_info_from_movie_url(movie_url, headers, movie_data)\n\u001b[0;32m     21\u001b[0m data\u001b[38;5;241m.\u001b[39mappend(movie_data)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(movie_data[\u001b[38;5;241m0\u001b[39m], movie_data[\u001b[38;5;241m1\u001b[39m])\n",
      "Cell \u001b[1;32mIn[22], line 27\u001b[0m, in \u001b[0;36mget_info_from_movie_url\u001b[1;34m(url, headers, movie_data)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_info_from_movie_url\u001b[39m(url, headers, movie_data):\n\u001b[1;32m---> 27\u001b[0m     response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(url, headers\u001b[38;5;241m=\u001b[39mheaders)\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;66;03m# print(response)\u001b[39;00m\n\u001b[0;32m     29\u001b[0m     soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(response\u001b[38;5;241m.\u001b[39mtext, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\rkart\\anaconda3\\Lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m request(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, params\u001b[38;5;241m=\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\rkart\\anaconda3\\Lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m session\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\rkart\\anaconda3\\Lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\rkart\\anaconda3\\Lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32mc:\\Users\\rkart\\anaconda3\\Lib\\site-packages\\requests\\adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[0;32m    668\u001b[0m         method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    669\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m    670\u001b[0m         body\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mbody,\n\u001b[0;32m    671\u001b[0m         headers\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    672\u001b[0m         redirect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    673\u001b[0m         assert_same_host\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    674\u001b[0m         preload_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    675\u001b[0m         decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    676\u001b[0m         retries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries,\n\u001b[0;32m    677\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    678\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    679\u001b[0m     )\n\u001b[0;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[1;32mc:\\Users\\rkart\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    784\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    786\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 787\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[0;32m    788\u001b[0m     conn,\n\u001b[0;32m    789\u001b[0m     method,\n\u001b[0;32m    790\u001b[0m     url,\n\u001b[0;32m    791\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[0;32m    792\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    793\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    794\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    795\u001b[0m     retries\u001b[38;5;241m=\u001b[39mretries,\n\u001b[0;32m    796\u001b[0m     response_conn\u001b[38;5;241m=\u001b[39mresponse_conn,\n\u001b[0;32m    797\u001b[0m     preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[0;32m    798\u001b[0m     decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[0;32m    799\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[0;32m    800\u001b[0m )\n\u001b[0;32m    802\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[0;32m    803\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\rkart\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:464\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    462\u001b[0m     \u001b[38;5;66;03m# Trigger any extra validation we need to do.\u001b[39;00m\n\u001b[0;32m    463\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 464\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_conn(conn)\n\u001b[0;32m    465\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    466\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mconn\u001b[38;5;241m.\u001b[39mtimeout)\n",
      "File \u001b[1;32mc:\\Users\\rkart\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:1093\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;66;03m# Force connect early to allow us to validate the connection.\u001b[39;00m\n\u001b[0;32m   1092\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_closed:\n\u001b[1;32m-> 1093\u001b[0m     conn\u001b[38;5;241m.\u001b[39mconnect()\n\u001b[0;32m   1095\u001b[0m \u001b[38;5;66;03m# TODO revise this, see https://github.com/urllib3/urllib3/issues/2791\u001b[39;00m\n\u001b[0;32m   1096\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_verified \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mproxy_is_verified:\n",
      "File \u001b[1;32mc:\\Users\\rkart\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py:753\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    751\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    752\u001b[0m     sock: socket\u001b[38;5;241m.\u001b[39msocket \u001b[38;5;241m|\u001b[39m ssl\u001b[38;5;241m.\u001b[39mSSLSocket\n\u001b[1;32m--> 753\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m sock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new_conn()\n\u001b[0;32m    754\u001b[0m     server_hostname: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\n\u001b[0;32m    755\u001b[0m     tls_in_tls \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\rkart\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py:198\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Establish a socket connection and set nodelay settings on it.\u001b[39;00m\n\u001b[0;32m    194\u001b[0m \n\u001b[0;32m    195\u001b[0m \u001b[38;5;124;03m:return: New socket connection.\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 198\u001b[0m     sock \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39mcreate_connection(\n\u001b[0;32m    199\u001b[0m         (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dns_host, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mport),\n\u001b[0;32m    200\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout,\n\u001b[0;32m    201\u001b[0m         source_address\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_address,\n\u001b[0;32m    202\u001b[0m         socket_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket_options,\n\u001b[0;32m    203\u001b[0m     )\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mgaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    205\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NameResolutionError(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost, \u001b[38;5;28mself\u001b[39m, e) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\rkart\\anaconda3\\Lib\\site-packages\\urllib3\\util\\connection.py:73\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m source_address:\n\u001b[0;32m     72\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[1;32m---> 73\u001b[0m sock\u001b[38;5;241m.\u001b[39mconnect(sa)\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n\u001b[0;32m     75\u001b[0m err \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/117.0\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "    \"Referer\": \"https://www.imdb.com/\",\n",
    "}\n",
    "\n",
    "for url in urls:\n",
    "    data = list()\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "    driver.get(url)\n",
    "    html = driver.page_source\n",
    "    driver.quit()\n",
    "    get_info_from_url(html, headers, data)\n",
    "    print('data', data)\n",
    "\n",
    "    with open(\"test.csv\", \"a\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.writer(f, delimiter=';')\n",
    "        writer.writerows(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ca48f9-c216-4814-8de2-35d3f4572a4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>place</th>\n",
       "      <th>title</th>\n",
       "      <th>rating</th>\n",
       "      <th>min</th>\n",
       "      <th>director</th>\n",
       "      <th>genre</th>\n",
       "      <th>release_date</th>\n",
       "      <th>origin_country</th>\n",
       "      <th>company</th>\n",
       "      <th>budget</th>\n",
       "      <th>gross_us</th>\n",
       "      <th>gross_world</th>\n",
       "      <th>open_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1975</td>\n",
       "      <td>1</td>\n",
       "      <td>Jaws</td>\n",
       "      <td>8.1</td>\n",
       "      <td>(124 min)</td>\n",
       "      <td>Steven Spielberg</td>\n",
       "      <td>['Disaster', 'Monster Horror', 'Sea Adventure'...</td>\n",
       "      <td>June 20, 1975 (United States)</td>\n",
       "      <td>United States</td>\n",
       "      <td>Zanuck/Brown Productions</td>\n",
       "      <td>$7,000,000 (estimated)</td>\n",
       "      <td>$280,083,300</td>\n",
       "      <td>$490,736,300</td>\n",
       "      <td>$7,061,513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1975</td>\n",
       "      <td>2</td>\n",
       "      <td>The Rocky Horror Picture Show</td>\n",
       "      <td>7.4</td>\n",
       "      <td>(100 min)</td>\n",
       "      <td>Jim Sharman</td>\n",
       "      <td>['B-Horror', 'Dark Comedy', 'Parody', 'Raunchy...</td>\n",
       "      <td>September 29, 1975 (United States)</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Twentieth Century Fox</td>\n",
       "      <td>$1,200,000 (estimated)</td>\n",
       "      <td>$113,028,197</td>\n",
       "      <td>$116,574,698</td>\n",
       "      <td>$135,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1975</td>\n",
       "      <td>3</td>\n",
       "      <td>One Flew Over the Cuckoo's Nest</td>\n",
       "      <td>8.6</td>\n",
       "      <td>(133 min)</td>\n",
       "      <td>Milos Forman</td>\n",
       "      <td>['Dark Comedy', 'Medical Drama', 'Psychologica...</td>\n",
       "      <td>November 21, 1975 (United States)</td>\n",
       "      <td>United States</td>\n",
       "      <td>Fantasy Films</td>\n",
       "      <td>$3,000,000 (estimated)</td>\n",
       "      <td>$108,981,275</td>\n",
       "      <td>$109,129,807</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1975</td>\n",
       "      <td>4</td>\n",
       "      <td>Dog Day Afternoon</td>\n",
       "      <td>8.0</td>\n",
       "      <td>(125 min)</td>\n",
       "      <td>Sidney Lumet</td>\n",
       "      <td>['Dark Comedy', 'Heist', 'True Crime', 'Biogra...</td>\n",
       "      <td>December 25, 1975 (United States)</td>\n",
       "      <td>United States</td>\n",
       "      <td>Warner Bros.</td>\n",
       "      <td>$1,800,000 (estimated)</td>\n",
       "      <td>$50,000,000</td>\n",
       "      <td>$50,009,617</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1975</td>\n",
       "      <td>5</td>\n",
       "      <td>Shampoo</td>\n",
       "      <td>6.4</td>\n",
       "      <td>(110 min)</td>\n",
       "      <td>Hal Ashby</td>\n",
       "      <td>['Satire', 'Comedy', 'Drama']</td>\n",
       "      <td>March 13, 1975 (United States)</td>\n",
       "      <td>United States</td>\n",
       "      <td>Persky-Bright / Vista</td>\n",
       "      <td>$4,000,000 (estimated)</td>\n",
       "      <td>$49,407,734</td>\n",
       "      <td>$49,407,734</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4870</th>\n",
       "      <td>2025</td>\n",
       "      <td>96</td>\n",
       "      <td>Eternity</td>\n",
       "      <td>7.2</td>\n",
       "      <td>(114 min)</td>\n",
       "      <td>David Freyne</td>\n",
       "      <td>['Feel-Good Romance', 'Romantic Comedy', 'Supe...</td>\n",
       "      <td>November 26, 2025 (United States)</td>\n",
       "      <td>United States</td>\n",
       "      <td>A24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$5,236,587</td>\n",
       "      <td>$5,433,602</td>\n",
       "      <td>$3,169,780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4871</th>\n",
       "      <td>2025</td>\n",
       "      <td>97</td>\n",
       "      <td>Hurry Up Tomorrow</td>\n",
       "      <td>4.4</td>\n",
       "      <td>(105 min)</td>\n",
       "      <td>Trey Edward Shults</td>\n",
       "      <td>['Psychological Thriller', 'Thriller']</td>\n",
       "      <td>May 16, 2025 (United States)</td>\n",
       "      <td>United States</td>\n",
       "      <td>Lionsgate</td>\n",
       "      <td>$15,000,000 (estimated)</td>\n",
       "      <td>$5,215,357</td>\n",
       "      <td>$7,763,862</td>\n",
       "      <td>$3,312,692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4872</th>\n",
       "      <td>2025</td>\n",
       "      <td>98</td>\n",
       "      <td>Light of the World</td>\n",
       "      <td>6.5</td>\n",
       "      <td>(91 min)</td>\n",
       "      <td>Tom Bancroft</td>\n",
       "      <td>['Hand-Drawn Animation', 'Animation', 'Drama',...</td>\n",
       "      <td>September 5, 2025 (United States)</td>\n",
       "      <td>United States</td>\n",
       "      <td>The Salvation Poem Project</td>\n",
       "      <td>$20,000,000 (estimated)</td>\n",
       "      <td>$5,213,377</td>\n",
       "      <td>$5,604,948</td>\n",
       "      <td>$2,401,374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4873</th>\n",
       "      <td>2025</td>\n",
       "      <td>99</td>\n",
       "      <td>Chhaava</td>\n",
       "      <td>7.3</td>\n",
       "      <td>(161 min)</td>\n",
       "      <td>Laxman Utekar</td>\n",
       "      <td>['Hindi', 'Action Epic', 'Costume Drama', 'Epi...</td>\n",
       "      <td>February 14, 2025 (India)</td>\n",
       "      <td>India</td>\n",
       "      <td>Maddock Films</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$4,800,000</td>\n",
       "      <td>$8,219,603</td>\n",
       "      <td>$1,790,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4874</th>\n",
       "      <td>2025</td>\n",
       "      <td>100</td>\n",
       "      <td>Stitch Head</td>\n",
       "      <td>5.8</td>\n",
       "      <td>(92 min)</td>\n",
       "      <td>Steve Hudson</td>\n",
       "      <td>['Computer Animation', 'Animation', 'Comedy', ...</td>\n",
       "      <td>October 29, 2025 (United States)</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Gringo Films</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$4,511,841</td>\n",
       "      <td>$6,330,164</td>\n",
       "      <td>$2,017,601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4875 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      year  place                            title  rating        min  \\\n",
       "0     1975      1                             Jaws     8.1  (124 min)   \n",
       "1     1975      2    The Rocky Horror Picture Show     7.4  (100 min)   \n",
       "2     1975      3  One Flew Over the Cuckoo's Nest     8.6  (133 min)   \n",
       "3     1975      4                Dog Day Afternoon     8.0  (125 min)   \n",
       "4     1975      5                          Shampoo     6.4  (110 min)   \n",
       "...    ...    ...                              ...     ...        ...   \n",
       "4870  2025     96                         Eternity     7.2  (114 min)   \n",
       "4871  2025     97                Hurry Up Tomorrow     4.4  (105 min)   \n",
       "4872  2025     98               Light of the World     6.5   (91 min)   \n",
       "4873  2025     99                          Chhaava     7.3  (161 min)   \n",
       "4874  2025    100                      Stitch Head     5.8   (92 min)   \n",
       "\n",
       "                director                                              genre  \\\n",
       "0       Steven Spielberg  ['Disaster', 'Monster Horror', 'Sea Adventure'...   \n",
       "1            Jim Sharman  ['B-Horror', 'Dark Comedy', 'Parody', 'Raunchy...   \n",
       "2           Milos Forman  ['Dark Comedy', 'Medical Drama', 'Psychologica...   \n",
       "3           Sidney Lumet  ['Dark Comedy', 'Heist', 'True Crime', 'Biogra...   \n",
       "4              Hal Ashby                      ['Satire', 'Comedy', 'Drama']   \n",
       "...                  ...                                                ...   \n",
       "4870        David Freyne  ['Feel-Good Romance', 'Romantic Comedy', 'Supe...   \n",
       "4871  Trey Edward Shults             ['Psychological Thriller', 'Thriller']   \n",
       "4872        Tom Bancroft  ['Hand-Drawn Animation', 'Animation', 'Drama',...   \n",
       "4873       Laxman Utekar  ['Hindi', 'Action Epic', 'Costume Drama', 'Epi...   \n",
       "4874        Steve Hudson  ['Computer Animation', 'Animation', 'Comedy', ...   \n",
       "\n",
       "                            release_date  origin_country  \\\n",
       "0          June 20, 1975 (United States)   United States   \n",
       "1     September 29, 1975 (United States)  United Kingdom   \n",
       "2      November 21, 1975 (United States)   United States   \n",
       "3      December 25, 1975 (United States)   United States   \n",
       "4         March 13, 1975 (United States)   United States   \n",
       "...                                  ...             ...   \n",
       "4870   November 26, 2025 (United States)   United States   \n",
       "4871        May 16, 2025 (United States)   United States   \n",
       "4872   September 5, 2025 (United States)   United States   \n",
       "4873           February 14, 2025 (India)           India   \n",
       "4874    October 29, 2025 (United States)  United Kingdom   \n",
       "\n",
       "                         company                   budget      gross_us  \\\n",
       "0       Zanuck/Brown Productions   $7,000,000 (estimated)  $280,083,300   \n",
       "1          Twentieth Century Fox   $1,200,000 (estimated)  $113,028,197   \n",
       "2                  Fantasy Films   $3,000,000 (estimated)  $108,981,275   \n",
       "3                   Warner Bros.   $1,800,000 (estimated)   $50,000,000   \n",
       "4          Persky-Bright / Vista   $4,000,000 (estimated)   $49,407,734   \n",
       "...                          ...                      ...           ...   \n",
       "4870                         A24                      NaN    $5,236,587   \n",
       "4871                   Lionsgate  $15,000,000 (estimated)    $5,215,357   \n",
       "4872  The Salvation Poem Project  $20,000,000 (estimated)    $5,213,377   \n",
       "4873               Maddock Films                      NaN    $4,800,000   \n",
       "4874                Gringo Films                      NaN    $4,511,841   \n",
       "\n",
       "       gross_world   open_week  \n",
       "0     $490,736,300  $7,061,513  \n",
       "1     $116,574,698    $135,000  \n",
       "2     $109,129,807         NaN  \n",
       "3      $50,009,617         NaN  \n",
       "4      $49,407,734         NaN  \n",
       "...            ...         ...  \n",
       "4870    $5,433,602  $3,169,780  \n",
       "4871    $7,763,862  $3,312,692  \n",
       "4872    $5,604,948  $2,401,374  \n",
       "4873    $8,219,603  $1,790,000  \n",
       "4874    $6,330,164  $2,017,601  \n",
       "\n",
       "[4875 rows x 14 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"test.csv\", delimiter = ';')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649ab0c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
